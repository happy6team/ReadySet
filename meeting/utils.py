# meeting_summarization/utils.py

import os
from pathlib import Path
from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë”© (ìµœì´ˆ 1íšŒë§Œ ë¡œë”©ë˜ë„ë¡ ìºì‹±)
_model = None
_tokenizer = None

def load_model():
    """
    KoBART ìš”ì•½ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œ ì‹œ ì¬ì‚¬ìš©ë©ë‹ˆë‹¤.
    """
    global _model, _tokenizer
    if _model is None or _tokenizer is None:
        print("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
        _model = BartForConditionalGeneration.from_pretrained("EbanLee/kobart-summary-v3")
        _tokenizer = PreTrainedTokenizerFast.from_pretrained("EbanLee/kobart-summary-v3")
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")
    return _model, _tokenizer

def file_upload_save(dir_path: str, upload_file) -> str:
    """
    ì—…ë¡œë“œëœ íŒŒì¼ì„ ì €ì¥í•˜ê³  ê²½ë¡œ ë°˜í™˜
    - dir_path: ì €ì¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    - upload_file: UploadFile ê°ì²´ ë˜ëŠ” íŒŒì¼ ê°ì²´
    """
    os.makedirs(dir_path, exist_ok=True)

    save_path = Path(dir_path) / upload_file.filename
    with open(save_path, "wb") as f:
        f.write(upload_file.file.read())  # FastAPI UploadFile ê¸°ì¤€
    return str(save_path)
