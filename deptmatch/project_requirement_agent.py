from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from dotenv import load_dotenv

load_dotenv()

# PDF ë¡œë”ë¡œ í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ë¬¸ì„œ ë¡œë“œ
def load_pdf_document(pdf_path):
    """PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        loader = PyPDFLoader(pdf_path)
        docs = loader.load()
        # ëª¨ë“  í˜ì´ì§€ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
        full_text = "\n".join([doc.page_content for doc in docs])
        return full_text
    except Exception as e:
        print(f"ë¬¸ì„œ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ í•¨ìˆ˜
def extract_project_requirements(text, model_name="gpt-4o-mini"):
    """í…ìŠ¤íŠ¸ì—ì„œ í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ"""
    # LLM ì„¤ì •
    llm = ChatOpenAI(model=model_name)
    
    # í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
    prompt = PromptTemplate(
        input_variables=["text"],
        template="""
ì•„ë˜ëŠ” ì—¬ëŸ¬ í”„ë¡œì íŠ¸ì˜ ìš”êµ¬ì‚¬í•­ì´ ë‹´ê¸´ PDF ë¬¸ì„œ ì›ë¬¸ì…ë‹ˆë‹¤.

{text}

ê° í”„ë¡œì íŠ¸ë³„ë¡œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”:
-project_id:          # ì˜ˆ: prj-001
-project_name:        # í”„ë¡œì íŠ¸ ì´ë¦„
-description:           # í”„ë¡œì íŠ¸ ì„¤ëª…
-roles:                 # ì—­í•  ëª©ë¡
-skills: [],                # í•„ìš” ê¸°ìˆ  ìŠ¤íƒ
-personality:           # ì„±ê²©ì  ìš”êµ¬ì‚¬í•­


ëª¨ë“  ì •ë³´ë¥¼ ë¹ ì§ì—†ì´ ì¶”ì¶œí•˜ê³ , ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
"""
    )
    
    # ì²´ì¸ ê²°í•©
    requirement_chain = prompt | llm
    
    # ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
    result = requirement_chain.invoke({"text": text})
    return result.content

# ì „ì²´ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ í•¨ìˆ˜
def extract_all_requirements(pdf_path=None):
    """PDFì—ì„œ ëª¨ë“  í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ"""
    if pdf_path is None:
        pdf_path="../vector_store/docs/project_requirement/project_requirements_kor.pdf"
        
    full_text = load_pdf_document(pdf_path)
    if not full_text:
        return "PDF ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
    # ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
    return extract_project_requirements(full_text)

# LangGraph Supervisorìš© invoke í•¨ìˆ˜
def invoke(state: dict, config) -> dict:
    """LangGraphì—ì„œ ì‚¬ìš©í•  invoke í•¨ìˆ˜"""
    # PDF ê²½ë¡œ ì„¤ì •
    pdf_path = state.get("pdf_path", "../vector_store/docs/project_requirement/project_requirements_kor.pdf")
    
    # ì´ë¯¸ ë¡œë“œëœ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
    full_text = load_pdf_document(pdf_path)
    if full_text:
        requirements = extract_project_requirements(full_text)
    else:
        requirements = "PDF ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
    # ì´ì „ ë©”ì‹œì§€ ìœ ì§€
    new_messages = list(state.get("messages", []))
    new_messages.append(f"ğŸ§  í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ê²°ê³¼:\n{requirements}")

    # thread_id ì„¤ì •
    thread_id = (
        getattr(config, "configurable", {}).get("thread_id")
        if hasattr(config, "configurable")
        else config.get("thread_id", "default")
    )

    return {
        **state,
        "messages": new_messages,
        "thread_id": thread_id,
    }

if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ ì¶”ì¶œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥
    result = extract_all_requirements()
    # LLMì˜ ì‘ë‹µ(content) ì¶œë ¥
    print("=== í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ê²°ê³¼ ===")
    print(result)