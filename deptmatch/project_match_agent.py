from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from dotenv import load_dotenv
from new_employee_agent import extract_applicant_profile
from project_requirement_agent import extract_all_requirements
import time

load_dotenv()

def project_matching(new_employee, projects, top_n):
    llm = ChatOpenAI(model="gpt-4o-mini") 

    prompt = PromptTemplate(
        input_variables=['new_employee', 'projects', 'top_n'],  # top_n ë³€ìˆ˜ ì¶”ê°€
        template="""
ë‹¤ìŒì€ í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì…ë‹ˆë‹¤.
{projects}

ë‹¤ìŒì€ ì‹ ì…ì‚¬ì›ì˜ í”„ë¡œí•„ ëª©ë¡ì…ë‹ˆë‹¤.
{new_employee}

ê° í”„ë¡œì íŠ¸ë³„ë¡œ ê°€ì¥ ì í•©í•œ ì‹ ì…ì‚¬ì› {top_n}ëª…ì„ ì„ ì •í•˜ê³  ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì„ ì • ê¸°ì¤€:
1. ê¸°ìˆ  ìŠ¤íƒ ì¼ì¹˜ë„ (40%)
2. ì—­í•  ì í•©ì„± (30%)
3. ì„±ê²©ì  ìš”êµ¬ì‚¬í•­ ë¶€í•©ë„ (20%)
4. í¬ë§ë¶€ì„œ ì¼ì¹˜ë„ (10%)

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
-í”„ë¡œì íŠ¸ID:
-í”„ë¡œì íŠ¸ëª…:
-ì¶”ì²œ ì¸ì¬: [
        ì‹ ì…ì‚¬ì› ì´ë¦„:
        ì¢…í•© ì ìˆ˜: 0.0    # 0.0~10.0 ì‚¬ì´ ì ìˆ˜
        í‰ê°€ í•­ëª©ë³„ ì ìˆ˜: 
            ê¸°ìˆ  ìŠ¤íƒ ì¼ì¹˜ë„: 0.0,    # 0.0~4.0
            ì—­í•  ì í•©ì„±: 0.0,         # 0.0~3.0
            ì„±ê²© ë¶€í•©ë„: 0.0,         # 0.0~2.0
            í¬ë§ë¶€ì„œ ì¼ì¹˜ë„: 0.0       # 0.0~1.0
        
        ì„ ì • ì´ìœ : 
            ìƒì„¸í•œ ì´ìœ  1,
            ìƒì„¸í•œ ì´ìœ  2,
            ìƒì„¸í•œ ì´ìœ  3
        
        ]
ë§¤ì¹­ ê³¼ì •ì—ì„œ ê° ê¸°ì¤€ë³„ ì ìˆ˜ë¥¼ ëª…í™•í•˜ê²Œ ê³„ì‚°í•˜ê³ , ê·¸ ê·¼ê±°ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ê° ì‹ ì…ì‚¬ì›ì´ í•´ë‹¹ í”„ë¡œì íŠ¸ì— ì™œ ì í•©í•œì§€ êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ ì œê³µí•˜ê³ , ê° ì„ ì • ê¸°ì¤€ì— ë”°ë¥¸ ì ìˆ˜ë¥¼ íˆ¬ëª…í•˜ê²Œ ë³´ì—¬ì£¼ì„¸ìš”.
"""
    )
    matching_chain = prompt | llm
    result = matching_chain.invoke({
        'new_employee': new_employee,
        'projects': projects, 
        'top_n': top_n
    })
    return result.content

def process_project_matching():
    # ì‹ ì…ì‚¬ì› í”„ë¡œí•„ ì¶”ì¶œ
    new_employee = extract_applicant_profile()
    # í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
    projects = extract_all_requirements()
    # ë§¤ì¹­ ì‹¤í–‰
    matching_result = project_matching(new_employee, projects, top_n=3)
    return matching_result

def invoke(state:dict, config) -> dict:
    project_matching_result = process_project_matching()

    new_messages = list(state.get("message",[]))
    new_messages.append(f"ğŸ§  í”„ë¡œì íŠ¸ë³„ ì¶”ì²œ ì¸ì¬ ê²°ê³¼:\n{project_matching_result}")

    # thread_id ì„¤ì •
    thread_id = (
        getattr(config, "configurable", {}).get("thread_id")
        if hasattr(config, "configurable")
        else config.get("thread_id", "default")
    )

    return {
        **state,
        "messages": new_messages,
        "thread_id": thread_id,
    }

if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ ì¶”ì¶œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥
    result = process_project_matching()
    # LLMì˜ ì‘ë‹µ(content) ì¶œë ¥
    print("=== í”„ë¡œì íŠ¸ ë§¤ì¹­ê²°ê³¼ ===")
    print(result)