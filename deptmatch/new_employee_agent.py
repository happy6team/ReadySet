from langchain_community.document_loaders import TextLoader
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from dotenv import load_dotenv

load_dotenv()

# í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”ë¡œ ì‹ ì…ì‚¬ì› í”„ë¡œí•„ ë¬¸ì„œ ë¡œë“œ
def load_text_document(text_path):
    """í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        with open(text_path, 'r', encoding='utf-8') as file:
            full_text = file.read()
        return full_text
    except Exception as e:
        print(f"ë¬¸ì„œ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# LLMì„ ì‚¬ìš©í•˜ì—¬ ì‹ ì…ì‚¬ì› ì •ë³´ ì¶”ì¶œ
def extract_applicant_info_llm(text, model_name="gpt-4o-mini"):
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‹ ì…ì‚¬ì› ì •ë³´ ì¶”ì¶œ"""
    # LLM ì„¤ì •
    llm = ChatOpenAI(model=model_name)
    
    # ì‹ ì…ì‚¬ì› ì •ë³´ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
    prompt = PromptTemplate(
        input_variables=["text"],
        template="""
ì•„ë˜ëŠ” ì‹ ì…ì‚¬ì› ì§€ì›ìë“¤ì˜ í”„ë¡œí•„ ì •ë³´ê°€ ë‹´ê¸´ í…ìŠ¤íŠ¸ ë¬¸ì„œì…ë‹ˆë‹¤.

{text}

ê° ì§€ì›ìë³„ë¡œ ë‹¤ìŒ JSONí˜•ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
- ì´ë¦„: ì‹ ì…ì‚¬ì› ì´ë¦„
- ì „ê³µ: í•™êµ ì „ê³µ
- ê¸°ìˆ  ìŠ¤íƒ: ì‹ ì…ì‚¬ì›ì´ ê°€ì§„ ê¸°ìˆ  ëª©ë¡
- ì—­í• : í¬ë§í•˜ëŠ” ì§ë¬´/ì—­í• 
- í¬ë§ë¶€ì„œ: 1ì§€ë§, 2ì§€ë§, 3ì§€ë§
- ì¸ì ì„±ê²€ì‚¬ ê²°ê³¼: ì˜ì‚¬ì†Œí†µ, ë…¼ë¦¬ë ¥, ì°½ì˜ë ¥, ë¦¬ë”ì‹­, ì±…ì„ê° ì ìˆ˜

ëª¨ë“  ì§€ì›ì ì •ë³´ë¥¼ ë¹ ì§ì—†ì´ ì¶”ì¶œí•˜ê³ , ì •í™•í•œ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
ë°˜ë“œì‹œ {text}ì— ìˆëŠ” ì‚¬ëŒ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
"""
    )
    
    # ì²´ì¸ ê²°í•©
    extraction_chain = prompt | llm
    
    # ì •ë³´ ì¶”ì¶œ
    result = extraction_chain.invoke({"text": text})
    return result

def extract_applicant_profile(text_path=None):
    if text_path is None:
        text_path = "../vector_store/docs/applicant_profiles/applicant_profiles.txt"

    full_text = load_text_document(text_path)
    if not full_text:
        return "í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
    return extract_applicant_info_llm(full_text)

def invoke(state:dict, config) -> dict:
    #.txt ê²½ë¡œ ì„¤ì •
    text_path = state.get("../vector_store/docs/applicant_profiles/applicant_profiles.txt")

    full_text = load_text_document(text_path)
    if full_text:
        new_employee = extract_applicant_profile(full_text)
    else:
        new_employee = "í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
    new_messages = list(state.get("message", []))
    new_messages.append(f"ğŸ§  í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ê²°ê³¼:\n{new_employee}")
        
    # thread_id ì„¤ì •
    thread_id = (
        getattr(config, "configurable", {}).get("thread_id")
        if hasattr(config, "configurable")
        else config.get("thread_id", "default")
    )

    return {
        **state,
        "messages": new_messages,
        "thread_id": thread_id,
    }

if __name__ == '__main__':
    result = extract_applicant_profile()
    print ("===ì‹ ì…ì‚¬ì› íŒŒì‹± ê²°ê³¼===")
    print(result)

