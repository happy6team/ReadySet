from typing import Literal, Optional, TypedDict, List
from langgraph.graph import StateGraph, END
from langchain_core.runnables import RunnableConfig
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

from agents.word_explain_agent import invoke as word_agent
from agents.code_check_agent import invoke as code_agent
from agents.exception_agent import invoke as exception_agent

from langchain_core.runnables.config import RunnableConfig

from dotenv import load_dotenv
from vector_store.builder import ensure_vector_db_exists
from vector_store.retrieval import test_vector_retrieval

class AgentState(TypedDict):
    input_query: str
    thread_id: str
    project_name: Optional[str]
    project_explain: Optional[str]
    messages: List[str]

# ë¼ìš°íŒ… í”„ë¡¬í”„íŠ¸ ì²´ì¸ ì •ì˜
router_prompt = PromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ ë˜ëŠ” ì½”ë“œ ì…ë ¥ì„ ë³´ê³  ì•„ë˜ ì¤‘ ì–´ë–¤ ê¸°ëŠ¥ì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ëŠ” AI ë¼ìš°í„°ì…ë‹ˆë‹¤.
ê° ê¸°ëŠ¥ì˜ ëª©ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

1. word_explain: í”„ë¡œì íŠ¸ ê´€ë ¨ ìš©ì–´ë‚˜ ê°œë… ì„¤ëª…
2. code_check: ì‚¬ìš©ìê°€ ì‘ì„±í•œ ì½”ë“œì— ëŒ€í•´ ê·œì¹™ ê²€í† 
3. exception_agent: ì–´ë–¤ ê¸°ëŠ¥ì—ë„ í•´ë‹¹í•˜ì§€ ì•ŠìŒ

ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©ì´ ì½”ë“œì²˜ëŸ¼ ë³´ì´ë©´ 'code_check'ë¡œ íŒë‹¨í•˜ì„¸ìš”.

ë‹¤ìŒ ì‚¬ìš©ì ì…ë ¥ì— ê°€ì¥ ì í•©í•œ ê¸°ëŠ¥ ì´ë¦„ë§Œ í•œ ë‹¨ì–´ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: code_check)

ì…ë ¥:
{input_query}
""")

router_chain = router_prompt | ChatOpenAI(model="gpt-4o-mini") | StrOutputParser()

# ë¼ìš°íŒ… í•¨ìˆ˜

def route_agent(state: AgentState) -> Literal["word_explain", "code_check", "exception_agent"]:
    result = router_chain.invoke({"input_query": state["input_query"]}).strip().lower()

    print(f"ğŸ§­ ë¼ìš°íŒ… ê²°ê³¼: {result}")  # ğŸ” Debug ì¶œë ¥

    if result in {"word_explain", "code_check"}:
        return result
    return "exception_agent"


# Supervisor Graph ìƒì„± í•¨ìˆ˜
from copy import deepcopy 

def create_supervisor_graph():
    builder = StateGraph(AgentState)

    def wrap_agent(agent_func):
        def wrapper(state: AgentState, config: RunnableConfig) -> AgentState:
            result = agent_func(state, config)
            new_state = deepcopy(state)

             # ê¸°ì¡´ ë©”ì‹œì§€ ìœ ì§€í•˜ê³  ë³‘í•©ë§Œ ìˆ˜í–‰
            new_state = state.copy()
            new_state["messages"] = result.get("messages", state.get("messages", []))

            return new_state
        return wrapper

    builder.add_node("word_explain", wrap_agent(word_agent))
    builder.add_node("code_check", wrap_agent(code_agent))
    builder.add_node("exception_agent", wrap_agent(exception_agent))

    builder.set_conditional_entry_point(route_agent)

    builder.add_edge("word_explain", END)
    builder.add_edge("code_check", END)
    builder.add_edge("exception_agent", END)

    return builder.compile()

def create_reports_vector_db():
    ensure_vector_db_exists("./vector_store/db/reports_chroma", "./vector_store/docs")

    # ë²¡í„° DB ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    results = test_vector_retrieval(
        query="ìŠ¤ë§ˆíŠ¸íŒœ í”„ë¡œì íŠ¸ì˜ ë‹¨ê³„ë³„ ì¶”ì§„ ì²´ê³„ì™€ ì±…ì„ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
        k=3,  # ìƒìœ„ 3ê°œ ê²°ê³¼ ê²€ìƒ‰
        db_path="./vector_store/db/reports_chroma"
    )
    print(results)
    

def main():
    load_dotenv()
    create_reports_vector_db()

    graph = create_supervisor_graph()

    # ì´ˆê¸° ìƒíƒœ ì •ì˜
    state = AgentState(
        input_query="ìŠ¤ë§ˆíŠ¸íŒœì´ ë­ì•¼?",
        thread_id="thread-001",
        project_name="ì°¨ì„¸ëŒ€ í•œêµ­í˜• ìŠ¤ë§ˆíŠ¸íŒœ ê°œë°œ",
        project_explain="ìŠ¤ë§ˆíŠ¸íŒœ ê¸°ìˆ ê°œë°œ í”„ë¡œì íŠ¸",
        messages=[]
    )

    # 1ì°¨: ìš©ì–´ ì„¤ëª… í…ŒìŠ¤íŠ¸
    state = graph.invoke(
        state,
        config=RunnableConfig(configurable={"thread_id": "thread-001"})
    )

    # 2ì°¨: ì½”ë“œ ê²€ìˆ˜ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ input ë³€ê²½
    state["input_query"] = """
class user_profile:
    def __init__(self):
        self.Name = "í™ê¸¸ë™"

def GetUserName():
    return self.Name
"""

    state = graph.invoke(
        state,
        config=RunnableConfig(configurable={"thread_id": "thread-001"})
    )

    # 3ì°¨: ì½”ë“œ ê²€ìˆ˜ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ input ë³€ê²½
    state["input_query"] = """ì˜¤ëŠ˜ ì ì‹¬ì´ ë­ì•¼?
"""
    state = graph.invoke(
        state,
        config=RunnableConfig(configurable={"thread_id": "thread-001"})
    )



    # ê²°ê³¼ ì¶œë ¥
    print("ğŸ’¬ ì €ì¥ëœ ë©”ì‹œì§€:")
    for i, msg in enumerate(state["messages"], 1):
        print(f"{i}. {msg}\n")

if __name__ == "__main__":
    main()